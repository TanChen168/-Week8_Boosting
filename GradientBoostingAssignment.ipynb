{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Gradient_Boosting_Assignment (Core).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanChen168/Week8_Boosting/blob/main/GradientBoostingAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1a1R3UyYQMH"
      },
      "source": [
        "# Intro to Gradient Boosting\n",
        "\n",
        "![gradient boosting image](https://media.geeksforgeeks.org/wp-content/uploads/20200721214745/gradientboosting.PNG)\n",
        "\n",
        "Image thanks to [Geeks for Geeks](https://www.geeksforgeeks.org/ml-gradient-boosting/)\n",
        "\n",
        "In this assignment you will:\n",
        "1. import and prepare a dataset for modeling\n",
        "2. test and evaluate 3 different boosting models and compare the fit times of each.\n",
        "3. tune the hyperparameters of the best model to reduce overfitting and improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBHKlzCubQOq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1guzybQJjbn6"
      },
      "source": [
        "In this assignment you will be working with census data.  Your goal is to predict whether a person will make more or less than $50k per year in income.\n",
        "\n",
        "The data is available [here](https://drive.google.com/file/d/1drlRzq-lIY7rxQnvv_3fsxfIfLsjQ4A-/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsllcFvrb7YC"
      },
      "source": [
        "# Get data\n",
        "df = pd.read_csv('/content/sample_data/census_income.csv')\n",
        "df = df.drop(columns='Unnamed: 0')\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6_1E6psj1J0"
      },
      "source": [
        "Prepare your dataset for modeling.\n",
        "\n",
        "Remember to: \n",
        "1. Check for missing data, bad data, and duplicates.\n",
        "2. Check your target class balance.\n",
        "3. Perform your validation split\n",
        "4. Create a preprocessing pipeline to use with your models.\n",
        "5. Fit and evaluate your models using pipelines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up bad data\n",
        "df = df[df.workclass != '?']\n",
        "df.info()"
      ],
      "metadata": {
        "id": "CTsTVGFpsNNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature and target dataset\n",
        "X = df.drop(columns = 'income-class')\n",
        "# Encode our target\n",
        "y = df['income-class']"
      ],
      "metadata": {
        "id": "Hg9CTBV-skPG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check target class balance\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "dVg2Xr8etsL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Wh3RssgPAu"
      },
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare and create pipeline\n",
        "\n",
        "# Initialize transformers\n",
        "num_selector = make_column_selector(dtype_include='number')\n",
        "cat_selector = make_column_selector(dtype_include='object')\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "freq_imputer = SimpleImputer(strategy='most_frequent')\n",
        "scaler = StandardScaler()\n",
        "ohe_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# This is the pipeline for numeric columns\n",
        "num_pipe = make_pipeline(mean_imputer, scaler)\n",
        "# This is the pipeline for categorical columns\n",
        "cat_pipe = make_pipeline(freq_imputer, ohe_encoder)\n",
        "\n",
        "#Column matching \n",
        "num_tuple = (num_pipe, num_selector)\n",
        "cat_tuple = (cat_pipe, cat_selector)\n",
        "column_transformer = make_column_transformer(num_tuple, cat_tuple)\n",
        "\n"
      ],
      "metadata": {
        "id": "7jAmza9tvYKw"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit gradient boosting classifier\n",
        "gbc = GradientBoostingClassifier()"
      ],
      "metadata": {
        "id": "5uElEJ-ixbY-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit gradient boosting classifier\n",
        "lgbm = LGBMClassifier()"
      ],
      "metadata": {
        "id": "Z7iEdNwSxdRd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit gradient boosting classifier\n",
        "xgb = XGBClassifier()"
      ],
      "metadata": {
        "id": "yaN06GO9xfbT"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_pipe = make_pipeline(column_transformer, gbc)\n",
        "lgbm_pipe = make_pipeline(column_transformer, lgbm)\n",
        "xgb_pipe = make_pipeline(column_transformer, xgb)"
      ],
      "metadata": {
        "id": "c6m4dbQBwpLW"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_pipe.fit(X_train, y_train)\n",
        "lgbm_pipe.fit(X_train, y_train)\n",
        "xgb_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DiYh6Xwx1wE",
        "outputId": "7d509dd8-5086-4828-bab7-13a0bea53479"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('pipeline-1',\n",
              "                                                  Pipeline(steps=[('simpleimputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6d092f1090>),\n",
              "                                                 ('pipeline-2',\n",
              "                                                  Pipeline(steps=[('simpleimputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('onehotencoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                                 sparse=False))]),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6d092f1050>)])),\n",
              "                ('xgbclassifier', XGBClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training accuracy:', gbc.score(X_train, y_train))\n",
        "print('Testing accuracy:', gbc.score(X_test, y_test))\n",
        "\n",
        "print('Training accuracy:', lgbm.score(X_train, y_train))\n",
        "print('Testing accuracy:', lgbm.score(X_test, y_test))\n",
        "\n",
        "print('Training accuracy:', xgb.score(X_train, y_train))\n",
        "print('Testing accuracy:', xgb.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Uyq5kzSPySfz",
        "outputId": "25bf9791-f5a4-4fa6-a31a-ad8671c1c60f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-ca43dbdc98cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('Testing accuracy:', gbc.score(X_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         result = self.predict_proba(X, raw_score, num_iteration,\n\u001b[0;32m--> 753\u001b[0;31m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \"\"\"\n\u001b[1;32m    799\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 800\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                              \u001b[0;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                              % (self._n_features, n_features))\n\u001b[0m\u001b[1;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[1;32m    607\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 105 and input n_features is 12 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dnM9v_Uh0IPi",
        "outputId": "935dfc63-4af2-411e-89a3-7205458a44be"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a8e9394-edad-4160-8fbc-a1567fa00a41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>35</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>9th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>29</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1590</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3300</th>\n",
              "      <td>31</td>\n",
              "      <td>Private</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>3325</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>37</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16202</th>\n",
              "      <td>19</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>Nicaragua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27802</th>\n",
              "      <td>19</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12229</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Separated</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802</th>\n",
              "      <td>52</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6388</th>\n",
              "      <td>41</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23043 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a8e9394-edad-4160-8fbc-a1567fa00a41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a8e9394-edad-4160-8fbc-a1567fa00a41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a8e9394-edad-4160-8fbc-a1567fa00a41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       age    workclass  ... hours-per-week native-country\n",
              "22      35  Federal-gov  ...             40  United-States\n",
              "13995   29      Private  ...             50  United-States\n",
              "3300    31      Private  ...             41  United-States\n",
              "8732    22      Private  ...             40  United-States\n",
              "184     37  Federal-gov  ...             42  United-States\n",
              "...    ...          ...  ...            ...            ...\n",
              "16202   19      Private  ...             30      Nicaragua\n",
              "27802   19      Private  ...             15  United-States\n",
              "12229   23      Private  ...             40  United-States\n",
              "1802    52      Private  ...             38  United-States\n",
              "6388    41      Private  ...             54  United-States\n",
              "\n",
              "[23043 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOIAxdz7k7d_"
      },
      "source": [
        "# eXtreme Gradient Boosting\n",
        "We are going to compare both metrics and fit times for our models.  Notice the 'cell magic' in the top of the cell below.  By putting `%%time` at the top of a notebook cell, we can tell it to output how long that cell took to run.  We can use this to compare the speed of each of our different models.  Fit times can be very important for models in deployment, especially with very large dataset and/or many features.\n",
        "\n",
        "Instantiate an eXtreme Gradient Boosting Classifier (XGBClassifier) below, fit it, and print out a classification report.  Take note of the accuracy, recall, precision, and f1-score, as well as the run time of the cell to compare to our next models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_JvXzBgHcU"
      },
      "source": [
        "%%time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtVjYZ54RjX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DdMdPlLgrVm"
      },
      "source": [
        "Which target class is your model better at predicting?  Is it significantly overfit?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWu_4o2nm-HP"
      },
      "source": [
        "# More Gradient Boosting\n",
        "\n",
        "Now fit and evaluate a Light Gradient Boosting Machine and a the Scikit Learn (sklearn) gradient boost model.  Remember to use the `%%time` cell magic command to get the run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpRP2a_UlTYX"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKxj1YCloRML"
      },
      "source": [
        "%%time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDkByQTB4QP_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iT6rGsjlWfC"
      },
      "source": [
        "## GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zcJ2pVoSUr"
      },
      "source": [
        "%%time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSvJ4frz4Q0P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9VNanqkoTf7"
      },
      "source": [
        "\n",
        "# Tuning Gradient Boosting Models\n",
        "\n",
        "Tree-based gradient boosting models have a LOT of hyperparameters to tune.  Here are the documentation pages for each of the 3 models you used today:\n",
        "\n",
        "1. [XGBoost Hyperparameter Documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
        "2. [LightGBM Hyperparameter Documentation](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)\n",
        "3. [Scikit-learn Gradient Boosting Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
        "\n",
        "Choose the model you felt performed the best when comparing multiple metrics and the runtime for fitting, and use GridSearchCV to try at least 2 different values each for 3 different hyper parameters in boosting model you chose.\n",
        "\n",
        "See if you can create a model with an accuracy between 86 and 90.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3M-SZpN_7iN"
      },
      "source": [
        "%%time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAV4kPhjHGf5"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Evaluate your model using a classifiation report and/or a confusion matrix.  Explain in text how your model performed in terms of precision, recall, and it's ability to predict each of the two classes.  Also talk about the benefits or drawbacks of the computation time of that model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQkGSUeEyEx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjtsxJQ5l7Hi"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this assignment you practiced:\n",
        "1. data cleaning\n",
        "2. instantiating, fitting, and evaluating boosting models using multiple metrics\n",
        "3. timing how long it takes a model to fit and comparing run times between multiple models\n",
        "4. and choosing a final model based on multiple metrics.\n",
        "\n"
      ]
    }
  ]
}